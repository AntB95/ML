{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from proj1_helpers import *\n",
    "from implementations import *\n",
    "from annexe import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = load_csv_data('/Users/bedanian/Desktop/Machine Learning/Project 1/train.csv', sub_sample = True)\n",
    "test_set = load_csv_data('/Users/bedanian/Desktop/Machine Learning/Project 1/test.csv', sub_sample = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(data_set, indice):\n",
    "    y_set = data_set[0]\n",
    "    x_set = data_set[1]\n",
    "    id_set = data_set[2]\n",
    "    return (y_set[x_set[:,22] == indice],x_set[x_set[:,22] == indice],id_set[x_set[:,22] == indice])\n",
    "\n",
    "def replace_mean(x_set):\n",
    "    x_set[x_set == -999] = np.nan\n",
    "    list_mean = x_set.mean(axis = 0)\n",
    "    for i in range(0,len(list_mean)):\n",
    "        x_set[np.isnan(x_set[:,i])] = list_mean[i]\n",
    "    return x_set\n",
    "\n",
    "def get_na_columns(array, threshold, value):\n",
    "    na_indices = []\n",
    "    for ind, row in enumerate(array.T):\n",
    "        count_na = 0\n",
    "        for j in range(len(row)):\n",
    "            if row[j] == value:\n",
    "                count_na += 1\n",
    "        if (count_na/len(row)) > threshold:\n",
    "            na_indices.append(ind)\n",
    "    return na_indices\n",
    "\n",
    "def standardize(x_train, x_test):\n",
    "    mean = np.mean(x_train)\n",
    "    norm = np.linalg.norm(x_train)\n",
    "    x_train_std = (x_train - mean)/norm\n",
    "    x_test_std = (x_test - mean)/norm\n",
    "    return x_train_std, x_test_std\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 0.5 * (1 + np.tanh(0.5*x))\n",
    "\n",
    "def zero_to_neg(array):\n",
    "    ret = np.zeros(len(array))\n",
    "    for i, v in enumerate(array):\n",
    "        if v == 0:\n",
    "            ret[i] = -1\n",
    "        else:\n",
    "            ret[i] = v\n",
    "    return ret\n",
    "\n",
    "def dummy(array,index,trigger):\n",
    "    (array[:,index][array[:,index] < trigger],array[:,index][array[:,index] > trigger]) = (0,1)\n",
    "    return array\n",
    "\n",
    "def build_poly(x, degree):\n",
    "    poly = x\n",
    "    for deg in range(2, degree+1):\n",
    "        poly = np.concatenate((poly, np.power(x, deg)), axis = 1)\n",
    "    return poly\n",
    "\n",
    "def add_function(x):\n",
    "    return np.concatenate((x,np.sin(x),np.cos(x),np.exp(x)), axis = 1)\n",
    "\n",
    "def store_columns(array,index):\n",
    "    store = array[:,index]\n",
    "    array = np.delete(array, [index] , axis = 1)\n",
    "    return (store,array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocessing\n",
    "#split the datset based on column 22 value\n",
    "#train\n",
    "(y_train_0,x_train_0,id_train_0) = split(train_set, 0)\n",
    "(y_train_1,x_train_1,id_train_1) = split(train_set, 1)\n",
    "(y_train_2,x_train_2,id_train_2) = split(train_set, 2)\n",
    "(y_train_3,x_train_3,id_train_3) = split(train_set, 3)\n",
    "#test\n",
    "(y_test_0,x_test_0,id_test_0) = split(test_set, 0)\n",
    "(y_test_1,x_test_1,id_test_1) = split(test_set, 1)\n",
    "(y_test_2,x_test_2,id_test_2) = split(test_set, 2)\n",
    "(y_test_3,x_test_3,id_test_3) = split(test_set, 3)\n",
    "\n",
    "#delete column 22\n",
    "x_train_0 = np.delete(x_train_0, [22] , axis = 1)\n",
    "x_train_1 = np.delete(x_train_1, [22] , axis = 1)\n",
    "x_train_2 = np.delete(x_train_2, [22] , axis = 1)\n",
    "x_train_3 = np.delete(x_train_3, [22] , axis = 1)\n",
    "\n",
    "x_test_0 = np.delete(x_test_0, [22] , axis = 1)\n",
    "x_test_1 = np.delete(x_test_1, [22] , axis = 1)\n",
    "x_test_2 = np.delete(x_test_2, [22] , axis = 1)\n",
    "x_test_3 = np.delete(x_test_3, [22] , axis = 1)\n",
    "\n",
    "#clean column of nan\n",
    "nan_0 = get_na_columns(x_train_0, 0.90, -999)\n",
    "x_train_0 = np.delete(x_train_0, nan_0 , axis = 1)\n",
    "x_test_0 = np.delete(x_test_0, nan_0 , axis = 1)\n",
    "\n",
    "nan_1 = get_na_columns(x_train_1, 0.90, -999)\n",
    "x_train_1 = np.delete(x_train_1, nan_1 , axis = 1)\n",
    "x_test_1 = np.delete(x_test_1, nan_1 , axis = 1)\n",
    "\n",
    "nan_2 = get_na_columns(x_train_2, 0.90, -999)\n",
    "x_train_2 = np.delete(x_train_2, nan_2, axis = 1)\n",
    "x_test_2 = np.delete(x_test_2, nan_2, axis = 1)\n",
    "\n",
    "nan_3 = get_na_columns(x_train_3, 0.90, -999)\n",
    "x_train_3 = np.delete(x_train_3, nan_3, axis = 1)\n",
    "x_test_3 = np.delete(x_test_3, nan_3, axis = 1)\n",
    "\n",
    "#cleaning last nan\n",
    "x_train_0 = replace_mean(x_train_0)\n",
    "x_train_1 = replace_mean(x_train_1)\n",
    "x_train_2 = replace_mean(x_train_2)\n",
    "x_train_3 = replace_mean(x_train_3)\n",
    "\n",
    "x_test_0 = replace_mean(x_test_0)\n",
    "x_test_1 = replace_mean(x_test_1)\n",
    "x_test_2 = replace_mean(x_test_2)\n",
    "x_test_3 = replace_mean(x_test_3)\n",
    "\n",
    "#x0\n",
    "#x_train_0 = dummy(x_train_0,4,20)\n",
    "#x_train_0 = np.delete(x_train_0, [7,8,10,11,13,14,16,18] , axis = 1)\n",
    "#x_train_0 = np.delete(x_train_0, [2,5] , axis = 1)\n",
    "\n",
    "#x_test_0 = dummy(x_test_0,4,20)\n",
    "#x_test_0 = np.delete(x_test_0, [7,8,10,11,13,14,16,18] , axis = 1)\n",
    "#x_test_0 = np.delete(x_test_0, [2,5] , axis = 1)\n",
    "\n",
    "#x1\n",
    "#x_train_1 = np.delete(x_train_1, [2,3,7,8,10,11,13,14,16,18,19,20] , axis = 1)\n",
    "#x_train_1 = dummy(x_train_1,2,20)\n",
    "#x_train_1[:,5] = np.log(x_train_1[:,5])\n",
    "\n",
    "#x_test_1 = np.delete(x_test_1, [2,3,7,8,10,11,13,14,16,18,19,20] , axis = 1)\n",
    "#x_test_1 = dummy(x_test_1,2,20)\n",
    "#x_test_1[:,5] = np.log(x_test_1[:,5])\n",
    "\n",
    "#x2\n",
    "#x_train_2 = np.delete(x_train_2, [2,7,10,11,12,14,15,17,18,20,23,24,26,27,28] , axis = 1)\n",
    "#x_train_2[:,3] = np.log(x_train_2[:,3])\n",
    "#x_train_2[:,13] = np.log(x_train_2[:,13])\n",
    "\n",
    "#x_test_2 = np.delete(x_test_2, [2,7,10,11,12,14,15,17,18,20,23,24,26,27,28] , axis = 1)\n",
    "#x_test_2[:,3] = np.log(x_test_2[:,3])\n",
    "#x_test_2[:,13] = np.log(x_test_2[:,13])\n",
    "\n",
    "#test x3\n",
    "#x_train_3 = np.delete(x_train_3, [2,6,7,10,11,12,14,15,17,18,20,21,23,24,26,27,28] , axis = 1)\n",
    "##x_train_3[:,3] = np.log(x_train_3[:,3])\n",
    "\n",
    "#x_test_3 = np.delete(x_test_3, [2,6,7,10,11,12,14,15,17,18,20,21,23,24,26,27,28] , axis = 1)\n",
    "#x_test_3[:,3] = np.log(x_test_3[:,3])\n",
    "\n",
    "\n",
    "#standardize\n",
    "(x_train_0,x_test_0) = standardize(x_train_0,x_test_0)\n",
    "(x_train_1,x_test_1) = standardize(x_train_1,x_test_1)\n",
    "(x_train_2,x_test_2) = standardize(x_train_2,x_test_2)\n",
    "(x_train_3,x_test_3) = standardize(x_train_3,x_test_3)\n",
    "\n",
    "#21.10.19\n",
    "(l0,d0) = [1e-12, 2]\n",
    "(l1,d1) = [4.691758698326445e-12, 2]\n",
    "(l2,d2) = [4.210291410564796e-14, 2]\n",
    "(l3,d3) = [0.00015581034821123352, 3]\n",
    "\n",
    "\n",
    "#polynome\n",
    "x_train_0 = build_poly(x_train_0, d0)\n",
    "x_train_1 = build_poly(x_train_1, d1)\n",
    "x_train_2 = build_poly(x_train_2, d2)\n",
    "x_train_3 = build_poly(x_train_3, d3)\n",
    "\n",
    "x_test_0 = build_poly(x_test_0, d0)\n",
    "x_test_1 = build_poly(x_test_1, d1)\n",
    "x_test_2 = build_poly(x_test_2, d2)\n",
    "x_test_3 = build_poly(x_test_3, d3)\n",
    "\n",
    "#add functions\n",
    "x_train_0 = add_function(x_train_0)\n",
    "x_test_0 = add_function(x_test_0)\n",
    "\n",
    "x_train_1 = add_function(x_train_1)\n",
    "x_test_1 = add_function(x_test_1)\n",
    "\n",
    "x_train_2 = add_function(x_train_2)\n",
    "x_test_2 = add_function(x_test_2)\n",
    "\n",
    "x_train_3 = add_function(x_train_3)\n",
    "x_test_3 = add_function(x_test_3)\n",
    "\n",
    "(w_0,_) = ridge_regression(y_train_0, x_train_0,l0)\n",
    "(w_1,_) = ridge_regression(y_train_1, x_train_1,l1)\n",
    "(w_2,_) = ridge_regression(y_train_2, x_train_2,l2)\n",
    "(w_3,_) = ridge_regression(y_train_3, x_train_3,l3)\n",
    "\n",
    "y_0 = zero_to_neg(np.around(sigmoid(x_test_0 @ w_0)))\n",
    "y_1 = zero_to_neg(np.around(sigmoid(x_test_1 @ w_1)))\n",
    "y_2 = zero_to_neg(np.around(sigmoid(x_test_2 @ w_2)))\n",
    "y_3 = zero_to_neg(np.around(sigmoid(x_test_3 @ w_3)))\n",
    "\n",
    "y = np.concatenate((y_0,y_1,y_2,y_3))\n",
    "id_test = np.concatenate((id_test_0,id_test_1,id_test_2,id_test_3))\n",
    "create_csv_submission(id_test, y, 'prediction.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
