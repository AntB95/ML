{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from proj1_helpers import *\n",
    "from implementations import *\n",
    "from annexe import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = load_csv_data('/Users/bedanian/Desktop/Machine Learning/Project 1/train.csv', sub_sample = True)\n",
    "test_set = load_csv_data('/Users/bedanian/Desktop/Machine Learning/Project 1/test.csv', sub_sample = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocessing\n",
    "#split the datset based on column 22 value\n",
    "#train\n",
    "(y_train_0,x_train_0,id_train_0) = split(train_set, 0, 22)\n",
    "(y_train_1,x_train_1,id_train_1) = split(train_set, 1, 22)\n",
    "(y_train_2,x_train_2,id_train_2) = split(train_set, 2, 22)\n",
    "(y_train_3,x_train_3,id_train_3) = split(train_set, 3, 22)\n",
    "#test\n",
    "(y_test_0,x_test_0,id_test_0) = split(test_set, 0, 22)\n",
    "(y_test_1,x_test_1,id_test_1) = split(test_set, 1, 22)\n",
    "(y_test_2,x_test_2,id_test_2) = split(test_set, 2, 22)\n",
    "(y_test_3,x_test_3,id_test_3) = split(test_set, 3, 22)\n",
    "\n",
    "#delete column 22\n",
    "x_train_0 = np.delete(x_train_0, [22] , axis = 1)\n",
    "x_train_1 = np.delete(x_train_1, [22] , axis = 1)\n",
    "x_train_2 = np.delete(x_train_2, [22] , axis = 1)\n",
    "x_train_3 = np.delete(x_train_3, [22] , axis = 1)\n",
    "\n",
    "x_test_0 = np.delete(x_test_0, [22] , axis = 1)\n",
    "x_test_1 = np.delete(x_test_1, [22] , axis = 1)\n",
    "x_test_2 = np.delete(x_test_2, [22] , axis = 1)\n",
    "x_test_3 = np.delete(x_test_3, [22] , axis = 1)\n",
    "\n",
    "#clean column of nan\n",
    "nan_0 = get_na_columns(x_train_0, 0.90, -999)\n",
    "x_train_0 = np.delete(x_train_0, nan_0 , axis = 1)\n",
    "x_test_0 = np.delete(x_test_0, nan_0 , axis = 1)\n",
    "\n",
    "nan_1 = get_na_columns(x_train_1, 0.90, -999)\n",
    "x_train_1 = np.delete(x_train_1, nan_1 , axis = 1)\n",
    "x_test_1 = np.delete(x_test_1, nan_1 , axis = 1)\n",
    "\n",
    "nan_2 = get_na_columns(x_train_2, 0.90, -999)\n",
    "x_train_2 = np.delete(x_train_2, nan_2, axis = 1)\n",
    "x_test_2 = np.delete(x_test_2, nan_2, axis = 1)\n",
    "\n",
    "nan_3 = get_na_columns(x_train_3, 0.90, -999)\n",
    "x_train_3 = np.delete(x_train_3, nan_3, axis = 1)\n",
    "x_test_3 = np.delete(x_test_3, nan_3, axis = 1)\n",
    "\n",
    "#cleaning last nan\n",
    "x_train_0 = replace_mean(x_train_0)\n",
    "x_train_1 = replace_mean(x_train_1)\n",
    "x_train_2 = replace_mean(x_train_2)\n",
    "x_train_3 = replace_mean(x_train_3)\n",
    "\n",
    "x_test_0 = replace_mean(x_test_0)\n",
    "x_test_1 = replace_mean(x_test_1)\n",
    "x_test_2 = replace_mean(x_test_2)\n",
    "x_test_3 = replace_mean(x_test_3)\n",
    "\n",
    "#x0\n",
    "x_train_0 = np.delete(x_train_0, [18] , axis = 1)\n",
    "x_test_0 = np.delete(x_test_0, [18] , axis = 1)\n",
    "\n",
    "\n",
    "#standardize\n",
    "(x_train_0,x_test_0) = standardize(x_train_0,x_test_0)\n",
    "(x_train_1,x_test_1) = standardize(x_train_1,x_test_1)\n",
    "(x_train_2,x_test_2) = standardize(x_train_2,x_test_2)\n",
    "(x_train_3,x_test_3) = standardize(x_train_3,x_test_3)\n",
    "\n",
    "\n",
    "(l0,d0) = [1e-12, 2]\n",
    "(l1,d1) = [4.691758698326445e-12, 2]\n",
    "(l2,d2) = [4.210291410564796e-14, 2]\n",
    "(l3,d3) = [0.00015581034821123352, 3]\n",
    "\n",
    "\n",
    "#polynome\n",
    "x_train_0 = build_poly(x_train_0, d0)\n",
    "x_train_1 = build_poly(x_train_1, d1)\n",
    "x_train_2 = build_poly(x_train_2, d2)\n",
    "x_train_3 = build_poly(x_train_3, d3)\n",
    "\n",
    "x_test_0 = build_poly(x_test_0, d0)\n",
    "x_test_1 = build_poly(x_test_1, d1)\n",
    "x_test_2 = build_poly(x_test_2, d2)\n",
    "x_test_3 = build_poly(x_test_3, d3)\n",
    "\n",
    "#add functions\n",
    "x_train_0 = add_function(x_train_0)\n",
    "x_test_0 = add_function(x_test_0)\n",
    "x_train_1 = add_function(x_train_1)\n",
    "x_test_1 = add_function(x_test_1)\n",
    "x_train_2 = add_function(x_train_2)\n",
    "x_test_2 = add_function(x_test_2)\n",
    "x_train_3 = add_function(x_train_3)\n",
    "x_test_3 = add_function(x_test_3)\n",
    "\n",
    "(w_0,_) = ridge_regression(y_train_0, x_train_0,l0)\n",
    "(w_1,_) = ridge_regression(y_train_1, x_train_1,l1)\n",
    "(w_2,_) = ridge_regression(y_train_2, x_train_2,l2)\n",
    "(w_3,_) = ridge_regression(y_train_3, x_train_3,l3)\n",
    "\n",
    "y_0 = zero_to_neg(np.around(sigmoid(x_test_0 @ w_0)))\n",
    "y_1 = zero_to_neg(np.around(sigmoid(x_test_1 @ w_1)))\n",
    "y_2 = zero_to_neg(np.around(sigmoid(x_test_2 @ w_2)))\n",
    "y_3 = zero_to_neg(np.around(sigmoid(x_test_3 @ w_3)))\n",
    "\n",
    "y = np.concatenate((y_0,y_1,y_2,y_3))\n",
    "id_test = np.concatenate((id_test_0,id_test_1,id_test_2,id_test_3))\n",
    "create_csv_submission(id_test, y, 'prediction.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
