{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!conda install -c conda-forge scikit-surprise\n",
    "\n",
    "#import package \n",
    "from surprise import SVD, NMF, Dataset, Reader, SVDpp, BaselineOnly, KNNBaseline, SlopeOne, accuracy\n",
    "from surprise.model_selection import cross_validate, GridSearchCV,train_test_split, KFold, GridSearchCV\n",
    "from sklearn.model_selection import KFold as skFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import RidgeCV, Ridge\n",
    "from project_helpers import *\n",
    "from math import *\n",
    "import pandas as pd \n",
    "\n",
    "#seed\n",
    "random.seed(404)\n",
    "np.random.seed(404)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we import data_train and we convert it in a surprise format\n",
    "train = pd.read_csv(r'data_train.csv')\n",
    "train = df_to_surprise(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split data into models training_set and blender_set 80% for train 20% for blending \n",
    "#traing_set was used to find the best hyperparameters using GS \n",
    "#the blender_set is used as a validation set for each model we compute on the traing_set but it also \n",
    "#use to compute a ridge regression and find the weight we will apply on each model. \n",
    "traing_set = train.sample(frac = 0.8, random_state = 200)\n",
    "blender_set = train.drop(traing_set.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we compute the global mean but also the mean by user and by movie\n",
    "mean = global_mean(traing_set)\n",
    "users = user_mean(traing_set)\n",
    "movies = movie_mean(traing_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change both dataset into the surprise format\n",
    "#setup the rating scale between 1 and 5\n",
    "reader = Reader(rating_scale = (1, 5))\n",
    "#surprise configuration\n",
    "traing_set_surp = Dataset.load_from_df(traing_set, reader)\n",
    "#load the traing_set as a full surprise trainset\n",
    "traing_set_surp_train = traing_set_surp.build_full_trainset()\n",
    "#surprise configuration\n",
    "blend_surp = Dataset.load_from_df(blender_set, reader)\n",
    "#load the blend as a full surprise trainset\n",
    "blend_surp_train = blend_surp.build_full_trainset()\n",
    "\n",
    "#Load blend train set as a testset for models performance evaluation\n",
    "blend_surp_test = blend_surp_train.build_testset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using sgd...\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    }
   ],
   "source": [
    "#fit on train set with parameters we found using grid search then we compute the prediction on the blending set\n",
    "bsl_options = {'method': 'sgd','reg': 10**-11}\n",
    "bsl_options_knnu = {'method': 'als','n_epochs': 50,}\n",
    "sim_options_knnu = {'name': 'pearson_baseline', 'user_based' : True}\n",
    "bsl_options_knni = {'method': 'als','n_epochs': 50,}\n",
    "sim_options_knni = {'name': 'pearson_baseline', 'user_based' : False}\n",
    "\n",
    "algo_baseline = BaselineOnly(bsl_options = bsl_options).fit(traing_set_surp_train)\n",
    "algo_slope_one = SlopeOne().fit(traing_set_surp_train)\n",
    "#KNN\n",
    "algo_knn_user = KNNBaseline(k = 400, sim_options = sim_options_knnu, bsl_options = bsl_options_knnu).fit(traing_set_surp_train)\n",
    "algo_knn_movie = KNNBaseline(k = 200, sim_options = sim_options_knni, bsl_options = bsl_options_knni).fit(traing_set_surp_train)\n",
    "#SVD\n",
    "#algo_SVD = SVD(reg_all = 0.01, biased = False, n_factors = 1, lr_all = 0.0015, n_epochs = 500, random_state = 200).fit(traing_set_surp_train)\n",
    "#algo_SVDpp = SVDpp(random_state = 200).fit(traing_set_surp_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVDb\n",
    "algo_SVDb = SVD(n_factors = 400, lr_all = 0.0015, biased = True, reg_all = 0.1, n_epochs = 400, random_state = 200).fit(traing_set_surp_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVDb pred\n",
    "predictions_SVDb = algo_SVDb.test(blend_surp_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo_NMFb = NMF(n_epochs = 400, biased = True).fit(traing_set_surp_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NMFb pred\n",
    "predictions_NMFb = algo_NMFb.test(blend_surp_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we compute the prediction on the blending set\n",
    "predictions_baseline = algo_baseline.test(blend_surp_test)\n",
    "#predictions_SVDb = algo_SVDb.test(blend_surp_test)\n",
    "#predictions_SVD = algo_SVD.test(blend_surp_test)\n",
    "#predictions_SVDpp = algo_SVDpp.test(blend_surp_test)\n",
    "predictions_slope_one = algo_slope_one.test(blend_surp_test)\n",
    "predictions_knn_user = algo_knn_user.test(blend_surp_test)\n",
    "predictions_knn_movie = algo_knn_movie.test(blend_surp_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Recover ids and estimations for each algorithm\n",
    "#extract user_id (uids) movie_id (mids) \n",
    "uids = [pred.uid for pred in predictions_baseline]\n",
    "mids = [pred.iid for pred in predictions_baseline]\n",
    "#extract the real grade\n",
    "ruis = [pred.r_ui for pred in predictions_baseline]\n",
    "\n",
    "est_baseline = [pred.est for pred in predictions_baseline]\n",
    "est_SVDb = [pred.est for pred in predictions_SVDb]\n",
    "#est_SVD = [pred.est for pred in predictions_SVD]\n",
    "#est_SVDpp = [pred.est for pred in predictions_SVDpp]\n",
    "est_slope_one = [pred.est for pred in predictions_slope_one]\n",
    "est_knn_user = [pred.est for pred in predictions_knn_user]\n",
    "est_knn_movie = [pred.est for pred in predictions_knn_movie]\n",
    "est_global = [mean for i in range(0,len(ruis))]\n",
    "est_user_mean = [predict_user(u, users, mean) for u in uids]\n",
    "est_movie_mean = [predict_movie(m, movies, mean) for m in mids]\n",
    "est_NMFb = [pred.est for pred in predictions_NMFb]\n",
    "\n",
    "#compute rmse score for the mean methods\n",
    "global_rmse = math.sqrt(sum([(x-y)**2 for (x,y) in zip(ruis, est_global)])/len(ruis))\n",
    "user_rmse = math.sqrt(sum([(x-y)**2 for (x,y) in zip(ruis, est_user_mean)])/len(ruis))\n",
    "movie_rmse = math.sqrt(sum([(x-y)**2 for (x,y) in zip(ruis, est_movie_mean)])/len(ruis))\n",
    "\n",
    "#we compute a matrix with all the 10 methods we use\n",
    "X = np.column_stack((est_global, est_user_mean, est_movie_mean, est_baseline, \n",
    "                     est_knn_movie, est_knn_user, est_slope_one,est_SVDb, est_NMFb))#, est_SVD, est_SVDpp))\n",
    "\n",
    "y = np.array(ruis)\n",
    "#we split the blending test in a train and test set 25% for the test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 200)\n",
    "\n",
    "#Cross validation and grid search for the ridge regression we fit for our blending\n",
    "cv_ridge = skFold(n_splits = 3, random_state = 200)\n",
    "gs_ridge = RidgeCV(alphas = [10**-i for i in range(-5,10)], fit_intercept = False, scoring = \"neg_mean_squared_error\", cv = cv_ridge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best lambda:  10.0\n",
      "Model blending RMSE on validation set:  0.9768643073647673\n"
     ]
    }
   ],
   "source": [
    "#We fit finds the best hyperparameter for the ridge regression then we obtain the weights we will use\n",
    "gs_ridge.fit(X_train, y_train)\n",
    "print('Best lambda: ', gs_ridge.alpha_)\n",
    "#we compute the rmse we obtain on the blend test set using the blending method\n",
    "preds_blend = gs_ridge.predict(X_test)\n",
    "#compute rmse for the blending\n",
    "blend_rmse = np.sqrt(np.mean((y_test-preds_blend)**2))\n",
    "print('Model blending RMSE on validation set: ', blend_rmse) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on baseline:  1.00329862204689\n",
      "RMSE SVDb:  0.9850157000056244\n",
      "RMSE Slope one:  0.999303955746321\n",
      "RMSE KNN user:  0.9919923488704668\n",
      "RMSE KNN movie:  0.9897453934926961\n",
      "Global mean RMSE on validation set:  1.119984536592249\n",
      "User mean RMSE on validation set:  1.095988679007401\n",
      "Movie mean RMSE on validation set:  1.0300326000124342\n",
      "RMSE on NMFb:  1.0149692594017745\n"
     ]
    }
   ],
   "source": [
    "#we compute the RMSE for each method\n",
    "print('RMSE on baseline: ', accuracy.rmse(predictions_baseline, verbose = False))\n",
    "print('RMSE SVDb: ', accuracy.rmse(predictions_SVDb, verbose = False))\n",
    "#print('RMSE SVD: ', accuracy.rmse(predictions_SVD, verbose = False))\n",
    "#print('RMSE SVDpp: ', accuracy.rmse(predictions_SVDpp, verbose = False))\n",
    "print('RMSE Slope one: ', accuracy.rmse(predictions_slope_one, verbose = False))\n",
    "print('RMSE KNN user: ', accuracy.rmse(predictions_knn_user, verbose = False))\n",
    "print('RMSE KNN movie: ', accuracy.rmse(predictions_knn_movie, verbose = False))\n",
    "print('Global mean RMSE on validation set: ', global_rmse)\n",
    "print('User mean RMSE on validation set: ', user_rmse)\n",
    "print('Movie mean RMSE on validation set: ', movie_rmse)\n",
    "print('RMSE on NMFb: ', accuracy.rmse(predictions_NMFb, verbose = False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
