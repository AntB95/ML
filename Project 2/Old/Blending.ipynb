{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'project_helpers'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-7a9cbc25b5b0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_model\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRidgeCV\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mproject_helpers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmath\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'project_helpers'"
     ]
    }
   ],
   "source": [
    "#!conda install -c conda-forge scikit-surprise\n",
    "\n",
    "#import package \n",
    "from surprise import SVD, NMF, Dataset, Reader, SVDpp, BaselineOnly, KNNBaseline, SlopeOne, accuracy\n",
    "from surprise.model_selection import cross_validate, GridSearchCV,train_test_split, KFold, GridSearchCV\n",
    "from sklearn.model_selection import KFold as skFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from project_helpers import *\n",
    "from math import *\n",
    "import pandas as pd \n",
    "\n",
    "#seed\n",
    "random.seed(404)\n",
    "np.random.seed(404)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-3870f80156fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#we import data_train and we convert it in a surprise format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'data_train.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_to_surprise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "#we import data_train and we convert it in a surprise format\n",
    "train = pd.read_csv(r'data_train.csv')\n",
    "train = df_to_surprise(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split data into models training_set and blender_set 80% for train 20% for blending \n",
    "#traing_set was used to find the best hyperparameters using GS \n",
    "#the blender_set is used as a validation set for each model we compute on the traing_set but it also \n",
    "#use to compute a ridge regression and find the weight we will apply on each model. \n",
    "traing_set = train.sample(frac = 0.8, random_state = 200)\n",
    "blender_set = train.drop(traing_set.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we compute the global mean but also the mean by user and by movie\n",
    "mean = global_mean(traing_set)\n",
    "users = user_mean(traing_set)\n",
    "movies = movie_mean(traing_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change both dataset into the surprise format\n",
    "#setup the rating scale between 1 and 5\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "#surprise configuration\n",
    "traing_set_surp = Dataset.load_from_df(traing_set, reader)\n",
    "#load the traing_set as a full surprise trainset\n",
    "traing_set_surp_train = traing_set_surp.build_full_trainset()\n",
    "#surprise configuration\n",
    "blend_surp = Dataset.load_from_df(blender_set, reader)\n",
    "#load the blend as a full surprise trainset\n",
    "blend_surp_train = blend_surp.build_full_trainset()\n",
    "\n",
    "#Load blend train set as a testset for models performance evaluation\n",
    "blend_surp_test = blend_surp_train.build_testset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using sgd...\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    }
   ],
   "source": [
    "#fit on train set with parameters we found using grid search then we compute the prediction on the blending set\n",
    "bsl_options = {'method': 'sgd','reg': 10**-11}\n",
    "bsl_options_knnu = {'method': 'als','n_epochs': 50,}\n",
    "sim_options_knnu = {'name': 'pearson_baseline', 'user_based' : True}\n",
    "bsl_options_knni = {'method': 'als','n_epochs': 50,}\n",
    "sim_options_knni = {'name': 'pearson_baseline', 'user_based' : False}\n",
    "\n",
    "algo_baseline = BaselineOnly(bsl_options = bsl_options).fit(traing_set_surp_train)\n",
    "algo_SVDb = SVD(n_factors = 400, lr_all = 0.0015, biased = True, reg_all = 0.1, n_epochs = 500, random_state = 200).fit(traing_set_surp_train)\n",
    "algo_SVD = SVD(reg_all = 0.01, biased = False, n_factors = 1, lr_all = 0.0015, n_epochs = 500, random_state = 200).fit(traing_set_surp_train)\n",
    "algo_SVDpp = SVDpp(random_state = 200).fit(traing_set_surp_train)\n",
    "algo_slope_one = SlopeOne().fit(traing_set_surp_train)\n",
    "algo_knn_user = KNNBaseline(k = 400, sim_options = sim_options_knnu, bsl_options = bsl_options_knnu).fit(traing_set_surp_train)\n",
    "algo_knn_movie = KNNBaseline(k = 200, sim_options = sim_options_knni, bsl_options = bsl_options_knni).fit(traing_set_surp_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we compute the prediction on the blending set\n",
    "predictions_baseline = algo_baseline.test(blend_surp_test)\n",
    "predictions_SVDb = algo_SVDb.test(blend_surp_test)\n",
    "predictions_SVD = algo_SVD.test(blend_surp_test)\n",
    "predictions_SVDpp = algo_SVDpp.test(blend_surp_test)\n",
    "predictions_slope_one = algo_slope_one.test(blend_surp_test)\n",
    "predictions_knn_user = algo_knn_user.test(blend_surp_test)\n",
    "predictions_knn_movie = algo_knn_movie.test(blend_surp_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Recover ids and estimations for each algorithm\n",
    "#extract user_id (uids) movie_id (mids) \n",
    "uids = [pred.uid for pred in predictions_baseline]\n",
    "mids = [pred.iid for pred in predictions_baseline]\n",
    "ruis = [pred.r_ui for pred in predictions_baseline]\n",
    "\n",
    "est_baseline = [pred.est for pred in predictions_baseline]\n",
    "est_SVDb = [pred.est for pred in predictions_SVDb]\n",
    "est_SVD = [pred.est for pred in predictions_SVD]\n",
    "est_SVDpp = [pred.est for pred in predictions_SVDpp]\n",
    "est_slope_one = [pred.est for pred in predictions_slope_one]\n",
    "est_knn_user = [pred.est for pred in predictions_knn_user]\n",
    "est_knn_movie = [pred.est for pred in predictions_knn_movie]\n",
    "est_global = [mean for i in range(0,len(ruis))]\n",
    "est_user_mean = [predict_user(u, users, mean) for u in uids]\n",
    "est_movie_mean = [predict_movie(m, movies, mean) for m in mids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute rmse score for the mean methods\n",
    "global_rmse = math.sqrt(sum([(a-b)**2 for (a,b) in zip(ruis, est_global)])/len(ruis))\n",
    "user_rmse = math.sqrt(sum([(a-b)**2 for (a,b) in zip(ruis, est_user_mean)])/len(ruis))\n",
    "movie_rmse = math.sqrt(sum([(a-b)**2 for (a,b) in zip(ruis, est_movie_mean)])/len(ruis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we compute a matrix with all the 10 methods we use\n",
    "X = np.column_stack((est_global, est_user_mean, est_movie_mean, est_baseline, \n",
    "                     est_knn_movie, est_knn_user, est_slope_one,\n",
    "                     est_SVDb, est_SVD, est_SVDpp))\n",
    "\n",
    "y = np.array(ruis)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cross validation iterator and grid search\n",
    "cv_ridge = skFold(n_splits = 3, random_state = 200)\n",
    "gs_ridge = RidgeCV(alphas = [10**-i for i in range(-5,10)], fit_intercept = False, scoring = \"neg_mean_squared_error\", cv = cv_ridge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best lambda:  10.0\n",
      "Weights:  [ 0.1186245  -0.23045774 -0.11948699 -0.28365135  0.15583958  0.17161256\n",
      "  0.18094706  1.03842627 -0.16405966  0.1300757 ]\n"
     ]
    }
   ],
   "source": [
    "#We fit finds the best hyperparameter then refit on the whole data\n",
    "gs_ridge.fit(X_train, y_train)\n",
    "print('Best lambda: ', gs_ridge.alpha_)\n",
    "print('Weights: ', gs_ridge.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model blending RMSE on validation set:  0.976919545735983\n"
     ]
    }
   ],
   "source": [
    "preds_blend = gs_ridge.predict(X_test)\n",
    "blend_rmse = np.sqrt(np.mean((y_test-preds_blend)**2))\n",
    "print('Model blending RMSE on validation set: ', blend_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
