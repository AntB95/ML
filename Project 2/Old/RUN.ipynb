{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import SVD, NMF, Dataset, Reader, SVDpp, BaselineOnly, KNNBaseline, SlopeOne, accuracy\n",
    "from surprise.model_selection import cross_validate, GridSearchCV,train_test_split, KFold, GridSearchCV\n",
    "from sklearn.model_selection import KFold as skFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import RidgeCV\n",
    "import pandas as pd \n",
    "from project_helpers import *\n",
    "from math import *\n",
    "\n",
    "#seed\n",
    "random.seed(404)\n",
    "np.random.seed(404)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the train set \n",
    "train = pd.read_csv('data_train.csv')\n",
    "train = df_to_surprise(train)\n",
    "#Convert the train set into Surprise\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "train_surp = Dataset.load_from_df(train, reader)\n",
    "train_surp = train_surp.build_full_trainset()\n",
    "train_surp_test = train_surp.build_testset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = global_mean(train)\n",
    "users = user_mean(train)\n",
    "movies = movie_mean(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using sgd...\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    }
   ],
   "source": [
    "#we train our different model on the train set with the parmaeters we found with the GS\n",
    "bsl_options = {'method': 'sgd','reg': 10**-11}\n",
    "bsl_options_knnu = {'method': 'als','n_epochs': 50,}\n",
    "sim_options_knnu = {'name': 'pearson_baseline', 'user_based' : True}\n",
    "bsl_options_knni = {'method': 'als','n_epochs': 50,}\n",
    "sim_options_knni = {'name': 'pearson_baseline', 'user_based' : False}\n",
    "\n",
    "algo_baseline = BaselineOnly(bsl_options = bsl_options).fit(train_surp)\n",
    "algo_SVDb = SVD(n_factors = 400, lr_all = 0.0015, biased = True, reg_all = 0.1, n_epochs = 500, random_state = 200).fit(train_surp)\n",
    "algo_SVD = SVD(reg_all = 0.01, biased = False, n_factors = 1, lr_all = 0.0015, n_epochs = 500, random_state = 200).fit(train_surp)\n",
    "algo_SVDpp = SVDpp(random_state = 200).fit(train_surp)\n",
    "algo_slope_one = SlopeOne().fit(train_surp)\n",
    "algo_knn_user = KNNBaseline(k = 400, sim_options = sim_options_knnu, bsl_options = bsl_options_knnu).fit(train_surp)\n",
    "algo_knn_movie = KNNBaseline(k = 200, sim_options = sim_options_knni, bsl_options = bsl_options_knni).fit(train_surp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the test set \n",
    "test_copy = pd.read_csv('sampleSubmission.csv')\n",
    "#convert test set to the surprise format\n",
    "test = test_copy.copy()\n",
    "test = df_to_surprise(test)\n",
    "test = Dataset.load_from_df(test, reader)\n",
    "test = test.build_full_trainset()\n",
    "test = test.build_testset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prediction for each model\n",
    "predictions_baseline = algo_baseline.test(test)\n",
    "predictions_SVDb = algo_SVDb.test(test)\n",
    "predictions_SVD = algo_SVD.test(test)\n",
    "predictions_SVDpp = algo_SVDpp.test(test)\n",
    "predictions_slope_one = algo_slope_one.test(test)\n",
    "predictions_knn_user = algo_knn_user.test(test)\n",
    "predictions_knn_movie = algo_knn_movie.test(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract estimated ratings\n",
    "uids = [pred.uid for pred in predictions_baseline]\n",
    "mids = [pred.iid for pred in predictions_baseline]\n",
    "ruis = [pred.r_ui for pred in predictions_baseline]\n",
    "est_baseline = [pred.est for pred in predictions_baseline]\n",
    "est_SVDb = [pred.est for pred in predictions_SVDb]\n",
    "est_SVD = [pred.est for pred in predictions_SVD]\n",
    "est_SVDpp = [pred.est for pred in predictions_SVDpp]\n",
    "est_slope_one = [pred.est for pred in predictions_slope_one]\n",
    "est_knn_user = [pred.est for pred in predictions_knn_user]\n",
    "est_knn_movie = [pred.est for pred in predictions_knn_movie]\n",
    "est_global = [mean for i in range(len(ruis))]\n",
    "est_user_mean = [predict_user(u, users, mean) for u in uids]\n",
    "est_movie_mean = [predict_movie(m, movies, mean) for m in mids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#matrix containing ratings predictions for each model \n",
    "est_baseline = np.array(est_baseline)\n",
    "est_global = np.array(est_global)\n",
    "est_user_mean = np.array(est_user_mean)\n",
    "est_movie_mean = np.array(est_movie_mean)\n",
    "est_knn_movie = np.array(est_knn_movie)\n",
    "est_knn_user = np.array(est_knn_user)\n",
    "est_slope_one = np.array(est_slope_one)\n",
    "est_SVDb = np.array(est_SVDb)\n",
    "est_SVD = np.array(est_SVD)\n",
    "est_SVDpp = np.array(est_SVDpp)\n",
    "\n",
    "X = np.column_stack((est_global, est_user_mean, est_movie_mean, est_baseline, est_knn_movie, est_knn_user\n",
    "                     , est_slope_one,est_SVDb, est_SVD, est_SVDpp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we constructe a linear combinaison of the 10 models we fit\n",
    "#weights\n",
    "weights = np.array([0.1186245, -0.23045774, -0.11948699,-0.28365135,0.15583958,0.17161256,\n",
    "  0.18094706,1.03842627,-0.16405966,0.1300757])\n",
    "preds = X.dot(weights)\n",
    "#Clip interval to 1-5 and round predictions to nearest integer\n",
    "preds = np.clip(preds, 1, 5)\n",
    "preds = np.around(preds)\n",
    "#Creating the id with the correct format\n",
    "ids = np.array(['r'+str(u)+'_c'+str(m) for (u,m) in zip(uids, mids)])\n",
    "#creating the submission\n",
    "sub = pd.DataFrame({'Id':ids, 'Prediction':preds})\n",
    "sub.to_csv('Submission.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
